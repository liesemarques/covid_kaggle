{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "covid_kaggle.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/liesemarques/covid_kaggle/blob/main/covid_kaggle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5jmLaaeK4Pc"
      },
      "source": [
        "# Carregamento da bibliotecas\n",
        "\n",
        "* numpy \n",
        "* pandas \n",
        "* glob\n",
        "* json\n",
        "* seaborn\n",
        "* spacy\n",
        "* nltk\n",
        "* matplotlib plt\n",
        "* from IPython.core.display import HTML\n",
        "\n",
        "\n",
        "# - Data Acquisition\n",
        "\n",
        "* Função p leitura dos arquivos json\n",
        "* Criação do DataFrame com os artigos json\n",
        "* Criação do CSV com os dados \n",
        "\n",
        "\n",
        "# - Text Extraction and Cleanup\n",
        "\n",
        "\n",
        "## Pre-processamento\n",
        "\n",
        "* Identificar e remover valores NaN, o DataFrame deve estar com textos completos\n",
        "* Remover valores duplicados\n",
        "* Retirar uma amostra da base de dados\n",
        "\n",
        "\n",
        "\n",
        "## Função para o pré-processamento\n",
        "* Criação de tokens 'tokenize'\n",
        "* Remoção das stop words \n",
        "* lematização\n",
        "* Named Entity Recognizer (NER) Nomeando entidades\n",
        "\n",
        "## Termos frequentes e Nuvem de Palavras\n",
        "\n",
        "* Identificar temos frequentes para uma possivel atualização da StopWords\n",
        "\n",
        "# - Evaluation\n",
        "* Pesquisas com uma palavra e NLTK\n",
        "* Pesquisa com 'find'\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMiG_WoCK4Pc"
      },
      "source": [
        "# Carregamento da bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "igjZJb-yK4Pd"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import glob\n",
        "import json\n",
        "import seaborn as sns\n",
        "import spacy\n",
        "import nltk\n",
        "from IPython.core.display import HTML\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Va3_ev-XK4Pd"
      },
      "source": [
        "## Instalação do scispaCy\n",
        "scispaCy é um pacote python que contem modelos spacy para processamento de textos biomédicos cientificos ou clinicos\n",
        "\n",
        "\n",
        "https://allenai.github.io/scispacy/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "m1GnmqMtK4Pd"
      },
      "source": [
        "!pip install scispacy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "KbH9IoutK4Pd"
      },
      "source": [
        "pip install spacy==2.2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "sws2J8ymK4Pd"
      },
      "source": [
        "import scispacy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W84GHf8vK4Pd"
      },
      "source": [
        "## Instalação do modelo en_core_sci_md\n",
        "Um pipeline spaCy completo para dados biomédicos com um vocabulário maior e vetores de 50 mil palavras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "jHFjmbriK4Pd"
      },
      "source": [
        "!pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.4/en_core_sci_md-0.2.4.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "GezyCxFiK4Pd"
      },
      "source": [
        "# Importando o modelo\n",
        "import en_core_sci_md"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "0u59WHV6K4Pd"
      },
      "source": [
        "!python -m spacy download en"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GloD4TlxK4Pd"
      },
      "source": [
        "--------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k64nbA8NK4Pd"
      },
      "source": [
        "## Criação do DataSet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Qck_j31mK4Pd"
      },
      "source": [
        "corona_features = {'paper_id': [], 'title': [],\n",
        "                   'abstract': [], 'text': []}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "7LLfYuXtK4Pd"
      },
      "source": [
        "corona_df = pd.DataFrame(corona_features)\n",
        "corona_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Fov9OfHmK4Pe"
      },
      "source": [
        "json_filenames = glob.glob(f'{\"/kaggle/input\"}//**/*.json', recursive = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "urlS2LlDK4Pe"
      },
      "source": [
        "len(json_filenames)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "pa9qkzZ6K4Pe"
      },
      "source": [
        "def return_corona_df(json_filenames, df):\n",
        "  for file_name in json_filenames:\n",
        "    row = {'paper_id': None, 'title': None,\n",
        "           'abstract': None, 'text': None}\n",
        "    \n",
        "    with open(file_name) as json_data:\n",
        "      \n",
        "      data = json.load(json_data)\n",
        "      \n",
        "      if 'paper_id' not in data:\n",
        "        row['paper_id'] = np.nan\n",
        "      else:\n",
        "        row['paper_id'] = data['paper_id'].strip() \n",
        "      \n",
        "      if 'metadata' not in data:\n",
        "        row['metadata'] = np.nan\n",
        "      else:  \n",
        "        row['title'] = data['metadata']['title'].strip()\n",
        " \n",
        "       \n",
        "      if 'abstract' not in data:\n",
        "        row['abstract'] = np.nan\n",
        "      else:\n",
        "          abstract_list = [abstract['text'] for abstract in data['abstract']]\n",
        "          abstract = '\\n '.join(abstract_list)\n",
        "          row['abstract'] = abstract.strip()\n",
        "   \n",
        "      if 'body_text' not in data:\n",
        "        row['body_text'] = np.nan\n",
        "      else:\n",
        "        text_list = [text['text'] for text in data['body_text']]\n",
        "        text = '\\n '.join(text_list)\n",
        "        row['text'] = text.strip()\n",
        "\n",
        "        df = df.append(row, ignore_index = True)\n",
        "  return df\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "slocQMpgK4Pe"
      },
      "source": [
        "corona_df = return_corona_df(json_filenames, corona_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "aIr0_F7sK4Pe"
      },
      "source": [
        "corona_df.to_csv('/kaggle/working/corona_df.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_E7usdZK4Pe"
      },
      "source": [
        "----------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1r7GizhGK4Pe"
      },
      "source": [
        "# - Text Extraction and Cleanup\n",
        "\n",
        "\n",
        "## Pre-processamento\n",
        "\n",
        "* Identificar e remover valores NaN, o DataFrame deve estar com textos completos\n",
        "* Remover valores duplicados\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "TFJE23plK4Pe"
      },
      "source": [
        "corona_df = pd.read_csv('../input/covid-text/corona_df.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "B1qPLr3jK4Pe"
      },
      "source": [
        "corona_df.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "nEBxs6rZK4Pe"
      },
      "source": [
        "corona_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "HH1-tfhtK4Pe"
      },
      "source": [
        "corona_df = corona_df.iloc[:,1:5]\n",
        "corona_df.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "i5EhhpgIK4Pe"
      },
      "source": [
        "corona_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "UMEtCsOXK4Pe"
      },
      "source": [
        "sns.heatmap(corona_df.isnull());"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "3r0j8WcSK4Pe"
      },
      "source": [
        "for i in corona_df.columns:\n",
        "    corona_df = corona_df[corona_df[i].notnull()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "3u2tRe3YK4Pe"
      },
      "source": [
        "corona_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "7ODJAou_K4Pe"
      },
      "source": [
        "corona_df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "8INmyXdDK4Pe"
      },
      "source": [
        "sns.heatmap(corona_df.isnull());"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "hP1u_XwRK4Pe"
      },
      "source": [
        "for i in corona_df.columns:\n",
        "    print(f\" Numeros de {i} vazio {len(corona_df[corona_df[i] == ''])}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "BknlfQeiK4Pe"
      },
      "source": [
        "corona_df.drop_duplicates(['abstract', 'text', 'title'], inplace = True)\n",
        "corona_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QccihkWK4Pe"
      },
      "source": [
        "# Amostra da base de dados\n",
        "Foi retirado uma mostra de 500 artigos aleatorios de 79099 artigos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "zo0q7HygK4Pe"
      },
      "source": [
        "# Corona_df contendo 500 artigos\n",
        "corona_df = corona_df.sample(n = 500, random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "nP_FQfkFK4Pe"
      },
      "source": [
        "corona_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "id": "qzNUNT41K4Pe"
      },
      "source": [
        "sample_text = corona_df['text'][119326]\n",
        "sample_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SmZAsG6K4Pf"
      },
      "source": [
        "# Função pre-processamento\n",
        "\n",
        "* tokenize - spaCy converte o texto em 'spacy.tokens.doc.Doc'\n",
        "https://spacy.io/api/tokenizer\n",
        "* stop words - Remoção da palavras menos relevantes em termos medicos\n",
        "* lemmatization - Estração dos radicais das palavras\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "-kLRuhxpK4Pf"
      },
      "source": [
        "# Modelo ja treinado do scispacy para textos medicos\n",
        "# Disable -\n",
        "# Sera usada somente remoção de stopwords nao sera necessario utilizar 'target' \n",
        "# 'parse' indica como uma palavra esta ligas a outra e não sera necessario\n",
        "# 'ner' reconhecimento de entidade sera feito mais adiante\n",
        "# https://spacy.io/usage/processing-pipelines#disabling\n",
        "nlp = en_core_sci_md.load(disable=['tagger', 'parser', 'ner'])\n",
        "nlp.max_length = 2000000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "YhCI3hSJK4Pf"
      },
      "source": [
        "# print(spacy.lang.en.stop_words.STOP_WORDS)\n",
        "# len(spacy.lang.en.stop_words.STOP_WORDS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "7sK9CwmKK4Pf"
      },
      "source": [
        "# Algumas palavras encontradas na nuvem de palavras que não estavam nas stop word do spacy\n",
        "new_stop_words = ['et', 'al', 'doi', 'copyright', 'http', 'https', 'fig', 'table', 'result', 'show']\n",
        "for word in new_stop_words:\n",
        "  nlp.vocab[word].is_stop = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "7PBB3OzUK4Pf"
      },
      "source": [
        "# 'lower()' Transforma todo o texto em minusculo\n",
        "# word.lemma_  extrai o radical das palavras\n",
        "# https://spacy.io/usage/linguistic-features\n",
        "\n",
        "def spacy_tokenizer(sentence):\n",
        "  sentence = sentence.lower()\n",
        "  list = []\n",
        "  list = [word.lemma_ for word in nlp(sentence) if not (word.is_stop or\n",
        "                                                        word.like_num or\n",
        "                                                        word.is_punct or\n",
        "                                                        word.is_space or\n",
        "                                                        len(word) == 1)]\n",
        "  list = ' '.join([str(element) for element in list])\n",
        "  return list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "id": "oFz-sezvK4Pf"
      },
      "source": [
        "# Texto oriiginal\n",
        "print(sample_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "id": "-Ym5qitjK4Pf"
      },
      "source": [
        "# texto processado\n",
        "test = sample_text\n",
        "result = spacy_tokenizer(test)\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "xoq6dqzyK4Pf"
      },
      "source": [
        "# Aplicando a função apcy_tokenizer em nossa base de 500 artigos\n",
        "corona_df['text'] = corona_df['text'].apply(spacy_tokenizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9EdoCwaK4Pf"
      },
      "source": [
        "# Termos frequentes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "XTpDN5k9K4Pf"
      },
      "source": [
        "for index, row in corona_df.iterrows():\n",
        "  # print(row['paper_id'], row['title'])\n",
        "  text_file = open('./' + row['paper_id'] + '.txt', 'w')\n",
        "  n = text_file.write(row['text'])\n",
        "  text_file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "2oxI8T5wK4Pf"
      },
      "source": [
        "from nltk.corpus import PlaintextCorpusReader\n",
        "corpus = PlaintextCorpusReader('./', '.*')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "5ecCk1POK4Pf"
      },
      "source": [
        "files = corpus.fileids()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "yeKBH6CcK4Pf"
      },
      "source": [
        "files[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "T_Y-ZpjYK4Pf"
      },
      "source": [
        "corpus.raw('00467bd1940aae7539467e3ae56a8210fd44fc80.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "hA7idPYmK4Pf"
      },
      "source": [
        "words = corpus.words()\n",
        "print(words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "qTnK53KqK4Pf"
      },
      "source": [
        "len(words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Migl7HVAK4Pf"
      },
      "source": [
        "frequency = nltk.FreqDist(words)\n",
        "most_common = frequency.most_common(100)\n",
        "most_common"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HH2yy5EBK4Pf"
      },
      "source": [
        "# Nuvem de palavras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "xfGVjp29K4Pf"
      },
      "source": [
        "from matplotlib.colors import ListedColormap\n",
        "color_map = ListedColormap(['orange', 'green', 'red', 'magenta'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "0nq0SA-PK4Pf"
      },
      "source": [
        "from wordcloud import WordCloud\n",
        "cloud = WordCloud(background_color = 'white', max_words=100, colormap=color_map)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "MIOhj87iK4Pf"
      },
      "source": [
        "cloud = cloud.generate(corona_df['text'].str.cat(sep='\\n'))\n",
        "plt.figure(figsize=(15,15))\n",
        "plt.imshow(cloud)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E35ftJCuK4Pf"
      },
      "source": [
        "# Extração de entidades nomeadas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKucp_oJK4Pf"
      },
      "source": [
        "Named Entity Recognizer (NER)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "5ZgeteiGK4Pf"
      },
      "source": [
        "text = str(corona_df['text'][119326])\n",
        "print(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "_DTvRvg9K4Pf"
      },
      "source": [
        "nlp_ent = spacy.load('en')\n",
        "nlp_ent.max_length = 2000000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "zEXL-PKZK4Pf"
      },
      "source": [
        "doc = nlp_ent(text)\n",
        "type(doc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Z5QCFPyEK4Pf"
      },
      "source": [
        "# Entidades contidas no texto de exemplo\n",
        "# https://spacy.io/api/annotation#named-entities\n",
        "# 'NORP' - NACIONALIDADE 'GPE' PAISES\n",
        "for entity in doc.ents:\n",
        "  if entity.label_ == 'NORP' or entity.label_ == 'GPE':\n",
        "    print(entity.text, entity.label_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "NzwD6ge6K4Pg"
      },
      "source": [
        "print(doc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "8OR_OrQaK4Pg"
      },
      "source": [
        "from spacy import displacy\n",
        "displacy.render(doc, style = 'ent')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8OA8dnAK4Pg"
      },
      "source": [
        "Contagem das entidades na base de dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "mSjmGqIPK4Pg"
      },
      "source": [
        "# poderia ser os ids\n",
        "gpe = []\n",
        "for index, row in corona_df.iterrows():\n",
        "    text = row['text']\n",
        "    doc = nlp_ent(text)\n",
        "    for entity in doc.ents:\n",
        "        if entity.label_ == 'GPE':\n",
        "            gpe.append(str(entity.text))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Mq13g-TbK4Pg"
      },
      "source": [
        "print(gpe)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "8A2r-fWvK4Pg"
      },
      "source": [
        "values_gpe, counts_gpe = np.unique(np.array(gpe), return_counts = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "9ar1nY-JK4Pg"
      },
      "source": [
        "gpe_df = pd.DataFrame({'value': values_gpe, 'counts': counts_gpe})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "zzbEE_G7K4Pg"
      },
      "source": [
        "gpe_df.head(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "QRPyj6DNK4Pg"
      },
      "source": [
        "gpe_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "FVE0Q1GwK4Pg"
      },
      "source": [
        "gpe_df_filtered = gpe_df[gpe_df.counts > 50]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "WpTLIivVK4Pg"
      },
      "source": [
        "gpe_df_filtered.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "U3xRr2fIK4Pg"
      },
      "source": [
        "gpe_df_filtered.head(16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "M5ZxShNkK4Pg"
      },
      "source": [
        "sns.set(rc={'figure.figsize': (15,8)})\n",
        "sns.barplot(x = 'value', y = 'counts', hue='value', data=gpe_df_filtered);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3s2F1su2K4Pg"
      },
      "source": [
        "# Textos utilizados para pesquisa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Lk8kyQiK4Pg"
      },
      "source": [
        "# Pesquisas com uma palavra e NLTK"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "vZVwT_R5K4Pg"
      },
      "source": [
        "# corpus c termos frequente\n",
        "text = nltk.Text(corpus.words())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "id": "vCb0r1yXK4Pg"
      },
      "source": [
        "match = text.concordance('smoke', width = 50, lines = 30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "TTf7-jEcK4Pg"
      },
      "source": [
        "# Função muito limitada\n",
        "type(match)\n",
        "# dir(match)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubSYSfuzK4Pg"
      },
      "source": [
        "# Pesquisa com 'find'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "HK8KDSVwK4Ph"
      },
      "source": [
        "string = corona_df['text'][119326]\n",
        "search_string = 'korea'\n",
        "print(string.find(search_string))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "-HlADsqXK4Ph"
      },
      "source": [
        "#dir(string)\n",
        "#help(string.find)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "EaLRd1xTK4Ph"
      },
      "source": [
        "string[13:13+10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "id": "tdL4j4nbK4Ph"
      },
      "source": [
        "string[13:13]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5e_3-9RK4Ph"
      },
      "source": [
        "# Aplicação na base de dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "bkY4_qBxK4Ph"
      },
      "source": [
        "search_string = 'Smoking'\n",
        "#search_string = 'Socio-economic'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "TvTMQ-waK4Ph"
      },
      "source": [
        "search_string = spacy_tokenizer(search_string)\n",
        "search_string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "SMj9NwR6K4Ph"
      },
      "source": [
        "def find_all_texts(input_str, search_str, number_of_words):\n",
        "  text_list = []\n",
        "  index = 0\n",
        "  number_of_words = number_of_words\n",
        "  while index < len(input_str):\n",
        "    i = input_str.find(search_str, index)\n",
        "    if i == -1:\n",
        "      return text_list\n",
        "    \n",
        "    if input_str[i-number_of_words:i] == '':\n",
        "      start = 0\n",
        "    else:\n",
        "      start = i - number_of_words\n",
        "\n",
        "    text_list.append(input_str[start:i] + input_str[i:i+number_of_words])\n",
        "    index = i + 1\n",
        "  return text_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "4s6z9k5SK4Pi"
      },
      "source": [
        "documents = []\n",
        "for index, row in corona_df.iterrows():\n",
        "  documents.append(find_all_texts(row['text'], search_string, 40))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "id": "OqIF1JQwK4Pi"
      },
      "source": [
        "for doc in documents:\n",
        "  if doc != []:\n",
        "    print(doc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "1ro0xIjNK4Pi"
      },
      "source": [
        "for index, row in corona_df.iterrows():\n",
        "  texts = find_all_texts(row['text'], search_string, 400)\n",
        "  if texts == []:\n",
        "    continue\n",
        "  \n",
        "  paper_id = row['paper_id']\n",
        "  title = row['title']\n",
        "  display(HTML(f'<h1>{search_string.upper()}</h1>'))\n",
        "  display(HTML(f\"\"\"<p>\n",
        "                      <strong>Titulo:</strong> {title}</br>\n",
        "                      <strong>ID:</strong> {paper_id}</br>\n",
        "                      <strong>Numero de vezes:</strong> {len(texts)}\n",
        "                   </p>\"\"\"))\n",
        "  for i in texts:\n",
        "    marked_text = str(i.replace(search_string, f\"<mark>{search_string}</mark>\"))\n",
        "    display(HTML(f\"\"\"<blockquote>... {marked_text} ...</blockquote>\"\"\"))  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "saszFiuUK4Pi"
      },
      "source": [
        "# Pesquisa com mais palavras e spaCy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6Z9T5mlK4Pi"
      },
      "source": [
        "## Testando o spaCy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "E8CQ5ts9K4Pi"
      },
      "source": [
        "search_strings = ['smoking','pulmonary disease']\n",
        "tokens_list = [nlp(spacy_tokenizer(item)) for item in search_strings]\n",
        "tokens_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "cB-eqlAPK4Pi"
      },
      "source": [
        "from spacy.matcher import PhraseMatcher\n",
        "matcher = PhraseMatcher(nlp.vocab)\n",
        "matcher.add('SEARCH', None, *tokens_list)\n",
        "numbers_of_words = 50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "2TjG3fpvK4Pi"
      },
      "source": [
        "search_string_html = ' '.join([str(element) for element in search_strings])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "857AxI2tK4Pi"
      },
      "source": [
        "for index, row in corona_df.iterrows():\n",
        "    marked_text = ''\n",
        "    doc = nlp(row['text'])\n",
        "    paper_id = row['paper_id']\n",
        "    title = row['title']\n",
        "    matches = matcher(doc)\n",
        "    if matches == []:\n",
        "        continue\n",
        "    display(HTML(f'<h1>{search_string_html.upper()}</h1>'))\n",
        "    display(HTML(f\"\"\"<p>\n",
        "                      <strong>Titulo:</strong> {title}</br>\n",
        "                      <strong>ID:</strong> {paper_id}</br>\n",
        "                      <strong>Numero de vezes:</strong> {len(matches)}\n",
        "                     </p>\"\"\"))\n",
        "    for i in matches:\n",
        "        start = i[1] - numbers_of_words\n",
        "        if start < 0 :\n",
        "            start = 0\n",
        "        for j in range(len(tokens_list)):\n",
        "            if doc[i[1]:i[2]].similarity(tokens_list[j]) == 1.0:\n",
        "                search_text = str(tokens_list[j])\n",
        "                marked_text = str(doc[start:i[2] + numbers_of_words]).replace(search_text, f\"<mark>{search_text}</mark>\")\n",
        "                marked_text += \"<br /><br /> \"\n",
        "    display(HTML(f\"\"\"<blockquote>...{marked_text}...</blockquote>\"\"\"))            "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "eMAwOgD0K4Pi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}